{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "766aaa81-96e6-42dc-b29d-8216d2a7feec",
   "metadata": {},
   "source": [
    "## 2.2 - Chain of Thought Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5201cd-7664-4cf4-b329-af5aa69a5c76",
   "metadata": {},
   "source": [
    "**Chain of Thought** (CoT) is a concept in natural language processing (NLP) that enables \n",
    "language models to reason through tasks in a structured, step-by-step manner, similar to human \n",
    "thinking. Rather than generating isolated responses, a model using Chain of Thought builds on \n",
    "prior information, creating responses that follow a logical flow and ensuring a coherent, \n",
    "context-aware dialogue. This approach is particularly valuable in complex or multi-step queries,\n",
    "where understanding and maintaining context over multiple interactions is essential.\n",
    "\n",
    "![LLM Tools](../../content/modules/ROOT/assets/images/04/04-02-cot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ece69d-0255-4232-9f1f-730a54b11453",
   "metadata": {},
   "source": [
    "## Why Chain of Thought Matters\n",
    "\n",
    "In traditional LLM models, responses can sometimes feel disjointed or context-free, especially with complex questions. Chain of Thought addresses these challenges by adding a reasoning layer, allowing the model to generate more accurate and relevant responses. This logical progression offers key benefits:\n",
    "\n",
    "1. **Coherence**: Responses follow a natural flow, making it easier for users to follow and engage with the conversation.\n",
    "2. **Context Retention**: By building on previous information, the model maintains context across multiple steps, crucial for handling complex questions.\n",
    "3. **Increased Accuracy**: Logical progression reduces the likelihood of irrelevant or incorrect information, enhancing the reliability of responses.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0022f3fb-ee50-40f2-b276-b8194668e49e",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a16ed2e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install -q langchain==0.1.9 openai==1.13.3\n",
    "# !pip install -q langchain-openai langchain\n",
    "#!pip uninstall langchain openai\n",
    "\n",
    "!pip install -q langchain-openai termcolor langchain_community duckduckgo_search wikipedia openapi-python-client langgraph langchain_experimental openai --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60bb3f0f-40b5-49a6-b493-5e361db0113e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import json\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from langchain.chains import LLMChain\n",
    "#from langchain_community.llms import VLLMOpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b908fd0-01dd-4ad2-b745-b3a4c56a7a7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# INFERENCE_SERVER_URL = os.getenv('API_URL')\n",
    "# MODEL_NAME = \"mistral-7b-instruct\"\n",
    "# API_KEY= os.getenv('API_KEY')\n",
    "\n",
    "INFERENCE_SERVER_URL = \"http://localhost:8000\"\n",
    "MODEL_NAME = \"ibm-granite/granite-3.0-8b-instruct\"\n",
    "API_KEY= \"alanliuxiang\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472b2f3f-ac23-4531-984b-6e8357233992",
   "metadata": {},
   "source": [
    "### Create the LLM instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01baa2b8-529d-455d-ad39-ef4a96dbaf97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LLM definition\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=API_KEY,\n",
    "    openai_api_base= f\"{INFERENCE_SERVER_URL}/v1\",\n",
    "    model_name=MODEL_NAME,\n",
    "    top_p=0.92,\n",
    "    temperature=0.01,\n",
    "    max_tokens=512,\n",
    "    presence_penalty=1.03,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d211bd1f-3e55-41ce-b3bc-0ee5db689c66",
   "metadata": {},
   "source": [
    "### Create the Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdd8bc4c-b353-4a51-a8b7-6cb348e19623",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template=\"\"\"<s>[INST]<<SYS>>\n",
    "You are a helpful, respectful and honest assistant. Always be as helpful as possible, while being safe.\n",
    "You will be asked a question, to which you must give an answer.\n",
    "Your answer should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content.\n",
    "Please ensure that your responses are socially unbiased and positive in nature.\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct but in a simple way and very concise\n",
    "If you don't know the answer to a question, answer \"I don't know\".\n",
    "<</SYS>>\n",
    "\n",
    "### QUESTION:\n",
    "{input}\n",
    "\n",
    "### ANSWER:\n",
    "[/INST]\n",
    "\"\"\"\n",
    "PROMPT_LLM = PromptTemplate(input_variables=[\"input\"], template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f875c62b-931a-402e-9494-98b7296f8b2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2493/2670321090.py:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  conversation = LLMChain(llm=llm,\n"
     ]
    }
   ],
   "source": [
    "conversation = LLMChain(llm=llm,\n",
    "                            prompt=PROMPT_LLM,\n",
    "                            verbose=False,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969484f2-1f55-4021-a995-1d529cf9cc54",
   "metadata": {},
   "source": [
    "### Let's ask a simple question **WITHOUT** Chain of Thought in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee09847d-9ff7-4181-ad11-96186bf0a322",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When designing a financial report based on the reports of larger Financial Service Institutions (FSIs), you should focus on the following key areas:\n",
      "\n",
      "1. **Financial Statements**: Review the income statement, balance sheet, and cash flow statement to understand the institution's financial performance, assets, liabilities, and cash flow.\n",
      "\n",
      "2. **Risk Management**: Analyze the institution's risk management strategies, including credit risk, market risk, operational risk, and liquidity risk.\n",
      "\n",
      "3. **Regulatory Compliance**: Ensure the institution adheres to relevant financial regulations and standards, such as Basel III, IFRS, or GAAP.\n",
      "\n",
      "4. **Profitability and Efficiency**: Evaluate the institution's profitability ratios (e.g., return on assets, return on equity) and efficiency ratios (e.g., cost-to-income ratio, asset turnover).\n",
      "\n",
      "5. **Capital Adequacy**: Assess the institution's capital adequacy ratio to ensure it has sufficient capital to cover potential losses and meet regulatory requirements.\n",
      "\n",
      "6. **Liquidity and Funding**: Examine the institution's liquidity position and funding sources to ensure it can meet short-term obligations and maintain long-term solvency.\n",
      "\n",
      "7. **Credit Quality**: Analyze the institution's loan portfolio, including loan loss provisions, non-performing loans, and credit quality trends.\n",
      "\n",
      "8. **Market Position**: Evaluate the institution's market position, competitive advantages, and growth opportunities in the financial services industry.\n",
      "\n",
      "9. **Corporate Governance**: Assess the institution's corporate governance practices, including board composition, executive compensation, and internal controls.\n",
      "\n",
      "10. **Sustainability and ESG**: Consider the institution's environmental, social, and governance (ESG) practices and their impact on long-term financial performance and risk management."
     ]
    }
   ],
   "source": [
    "first_input = \"I want to design a finantial report around the report from the larger FSIs. What I should focus?\"\n",
    "conversation.predict(input=first_input);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53514c74-27fd-48f7-8f74-dcc96b4856bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### LLM with Chain of Thought in the Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60ed6c44-a016-49bd-8623-f231c5bba5b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template=\"\"\"<s>[INST]<<SYS>>\n",
    "You are a helpful, respectful, and honest assistant. Always be as helpful as possible while being safe.\n",
    "You will be asked a question, to which you must give an answer.\n",
    "Your answer should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content.\n",
    "Please ensure that your responses are socially unbiased and positive in nature.\n",
    "When answering, think step-by-step and explain your reasoning before providing the final answer.\n",
    "Explain it with bullet points if it's needed but using reasoning and step-by-step.\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something incorrect.\n",
    "If you don't know the answer to a question, answer \"I don't know\".\n",
    "<</SYS>>\n",
    "\n",
    "### QUESTION:\n",
    "{input}\n",
    "\n",
    "### ANSWER:\n",
    "[/INST]\n",
    "\"\"\"\n",
    "PROMPT_COT = PromptTemplate(input_variables=[\"input\"], template=template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06992d19-a605-421b-a560-7082a3f12a6b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Chain of Thought Prompt\n",
    "\n",
    "Let's ask the same question with Chain of Thought\n",
    "\n",
    "* When answering, think step-by-step and explain your reasoning before providing the final answer.\n",
    "* Explain it with bullet points if it's needed but using reasoning and step-by-step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd3dba1b-7d9d-4c1f-b3f2-61b3385f7d7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conversation_cot = LLMChain(llm=llm,\n",
    "                            prompt=PROMPT_COT,\n",
    "                            verbose=False,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98984cb8-b119-4770-a948-2779f211c519",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. **Understand the Purpose**: The primary purpose of a financial report is to provide information about a company's financial performance and position. It should be clear, concise, and easy to understand.\n",
      "\n",
      "2. **Identify the Relevant Information**: Look for key financial metrics such as revenue, expenses, profits, losses, assets, liabilities, and equity. Also, consider non-financial information like market trends, competitive landscape, and strategic initiatives.\n",
      "\n",
      "3. **Compare with Larger FSIs**: Compare your company's financial performance with that of larger Financial Service Institutions (FSIs). This will help you understand your company's position in the market and identify areas for improvement.\n",
      "\n",
      "4. **Use Standard Formats**: Use standard financial reporting formats to ensure consistency and comparability. This could include income statements, balance sheets, cash flow statements, and statements of shareholders' equity.\n",
      "\n",
      "5. **Provide Context**: Provide context for your financial performance. This could include explanations for any significant changes in financial performance, discussions of market trends, and descriptions of strategic initiatives.\n",
      "\n",
      "6. **Ensure Accuracy**: Ensure that all financial information is accurate and has been reviewed by a qualified accountant or auditor.\n",
      "\n",
      "7. **Review and Revise**: Review your report for clarity, accuracy, and completeness. Make any necessary revisions before finalizing the report."
     ]
    }
   ],
   "source": [
    "first_input = \"I want to design a finantial report around the report from the larger FSIs. What I should focus?\"\n",
    "conversation_cot.predict(input=first_input);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06c4cad-c8c6-4368-80b9-1cc54195d20d",
   "metadata": {},
   "source": [
    "## Enhancing LLMs Performance with Chain of Thought\n",
    "\n",
    "By simulating a thought process, Chain of Thought enhances NLP models by:\n",
    "\n",
    "- **Improving Context Understanding**: The model remembers previous interactions, generating responses that are relevant and contextually aware.\n",
    "- **Boosting User Experience**: Users benefit from a more natural and satisfying interaction, as the model “thinks” through its responses.\n",
    "- **Increasing Flexibility**: CoT enables models to handle multi-part questions, making them versatile for applications like virtual assistants, customer service bots, and educational tools.\n",
    "\n",
    "Incorporating Chain of Thought into LLMs frameworks, such as LangChain, enables language models to tackle complex tasks, making them more effective for real-world applications where logical reasoning and clarity are paramount."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
